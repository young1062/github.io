<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.4 Autoencoders (AEs) | An Introduction to Unsupervised Learning</title>
  <meta name="description" content="An introductory text on the goals and methods of unsupervised learning" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="6.4 Autoencoders (AEs) | An Introduction to Unsupervised Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="An introductory text on the goals and methods of unsupervised learning" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.4 Autoencoders (AEs) | An Introduction to Unsupervised Learning" />
  
  <meta name="twitter:description" content="An introductory text on the goals and methods of unsupervised learning" />
  

<meta name="author" content="Alex Young and Cenhao Zhu" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="locally-linear-embeddings-lles.html"/>
<link rel="next" href="additional-methods.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.4/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>
<script src="libs/threejs-111/three.min.js"></script>
<script src="libs/threejs-111/Detector.js"></script>
<script src="libs/threejs-111/Projector.js"></script>
<script src="libs/threejs-111/CanvasRenderer.js"></script>
<script src="libs/threejs-111/TrackballControls.js"></script>
<script src="libs/threejs-111/StateOrbitControls.js"></script>
<script src="libs/scatterplotThree-binding-0.3.3/scatterplotThree.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Unsupervised Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>1.1</b> Prerequisites</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch-prob.html"><a href="ch-prob.html"><i class="fa fa-check"></i><b>2</b> Mathematical Background and Notation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="important-notation.html"><a href="important-notation.html"><i class="fa fa-check"></i><b>2.1</b> Important notation</a></li>
<li class="chapter" data-level="2.2" data-path="random-vectors-in-mathbbrd.html"><a href="random-vectors-in-mathbbrd.html"><i class="fa fa-check"></i><b>2.2</b> Random vectors in <span class="math inline">\(\mathbb{R}^d\)</span></a></li>
<li class="chapter" data-level="2.3" data-path="expectation-mean-and-covariance.html"><a href="expectation-mean-and-covariance.html"><i class="fa fa-check"></i><b>2.3</b> Expectation, Mean, and Covariance</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="expectation-mean-and-covariance.html"><a href="expectation-mean-and-covariance.html#sample-mean-and-sample-covariance"><i class="fa fa-check"></i><b>2.3.1</b> Sample Mean and Sample Covariance</a></li>
<li class="chapter" data-level="2.3.2" data-path="expectation-mean-and-covariance.html"><a href="expectation-mean-and-covariance.html#the-data-matrix"><i class="fa fa-check"></i><b>2.3.2</b> The Data Matrix</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="linear-algebra.html"><a href="linear-algebra.html"><i class="fa fa-check"></i><b>2.4</b> Linear Algebra</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="linear-algebra.html"><a href="linear-algebra.html#assumed-background"><i class="fa fa-check"></i><b>2.4.1</b> Assumed Background</a></li>
<li class="chapter" data-level="2.4.2" data-path="linear-algebra.html"><a href="linear-algebra.html#interpretations-of-matrix-multiplication"><i class="fa fa-check"></i><b>2.4.2</b> Interpretations of Matrix Multiplication</a></li>
<li class="chapter" data-level="2.4.3" data-path="linear-algebra.html"><a href="linear-algebra.html#norms-and-distances"><i class="fa fa-check"></i><b>2.4.3</b> Norms and Distances</a></li>
<li class="chapter" data-level="2.4.4" data-path="linear-algebra.html"><a href="linear-algebra.html#important-properties"><i class="fa fa-check"></i><b>2.4.4</b> Important properties</a></li>
<li class="chapter" data-level="2.4.5" data-path="linear-algebra.html"><a href="linear-algebra.html#matrix-factorizations"><i class="fa fa-check"></i><b>2.4.5</b> Matrix Factorizations</a></li>
<li class="chapter" data-level="2.4.6" data-path="linear-algebra.html"><a href="linear-algebra.html#positive-definiteness-and-matrix-powers"><i class="fa fa-check"></i><b>2.4.6</b> Positive Definiteness and Matrix Powers</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>2.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="central-goals-and-assumptions.html"><a href="central-goals-and-assumptions.html"><i class="fa fa-check"></i><b>3</b> Central goals and assumptions</a>
<ul>
<li class="chapter" data-level="3.1" data-path="dimension-reduction-and-manifold-learning.html"><a href="dimension-reduction-and-manifold-learning.html"><i class="fa fa-check"></i><b>3.1</b> Dimension reduction and manifold learning</a></li>
<li class="chapter" data-level="3.2" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>3.2</b> Clustering</a></li>
<li class="chapter" data-level="3.3" data-path="generating-synthetic-data.html"><a href="generating-synthetic-data.html"><i class="fa fa-check"></i><b>3.3</b> Generating synthetic data</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="generating-synthetic-data.html"><a href="generating-synthetic-data.html#data-on-manifolds"><i class="fa fa-check"></i><b>3.3.1</b> Data on manifolds</a></li>
<li class="chapter" data-level="3.3.2" data-path="generating-synthetic-data.html"><a href="generating-synthetic-data.html#clustered-data"><i class="fa fa-check"></i><b>3.3.2</b> Clustered data</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>3.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-linear.html"><a href="ch-linear.html"><i class="fa fa-check"></i><b>4</b> Linear Methods</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sec-pca.html"><a href="sec-pca.html"><i class="fa fa-check"></i><b>4.1</b> Principal Component Analysis</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="sec-pca.html"><a href="sec-pca.html#derivation-using-iterative-projections"><i class="fa fa-check"></i><b>4.1.1</b> Derivation using Iterative Projections</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec-svd.html"><a href="sec-svd.html"><i class="fa fa-check"></i><b>4.2</b> Singular Value Decomposition</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="sec-svd.html"><a href="sec-svd.html#low-rank-approximations"><i class="fa fa-check"></i><b>4.2.1</b> Low-rank approximations</a></li>
<li class="chapter" data-level="4.2.2" data-path="sec-svd.html"><a href="sec-svd.html#svd-and-low-rank-approximations"><i class="fa fa-check"></i><b>4.2.2</b> SVD and Low Rank Approximations</a></li>
<li class="chapter" data-level="4.2.3" data-path="sec-svd.html"><a href="sec-svd.html#connections-with-pca"><i class="fa fa-check"></i><b>4.2.3</b> Connections with PCA</a></li>
<li class="chapter" data-level="4.2.4" data-path="sec-svd.html"><a href="sec-svd.html#recommender-systems"><i class="fa fa-check"></i><b>4.2.4</b> Recommender Systems</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="nonnegative-matrix-factorization.html"><a href="nonnegative-matrix-factorization.html"><i class="fa fa-check"></i><b>4.3</b> Nonnegative Matrix Factorization</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="nonnegative-matrix-factorization.html"><a href="nonnegative-matrix-factorization.html#interpretability-superpositions-and-positive-spans"><i class="fa fa-check"></i><b>4.3.1</b> Interpretability, Superpositions, and Positive Spans</a></li>
<li class="chapter" data-level="4.3.2" data-path="nonnegative-matrix-factorization.html"><a href="nonnegative-matrix-factorization.html#geometric-interpretation"><i class="fa fa-check"></i><b>4.3.2</b> Geometric Interpretation</a></li>
<li class="chapter" data-level="4.3.3" data-path="nonnegative-matrix-factorization.html"><a href="nonnegative-matrix-factorization.html#finding-an-nmf-multiplicative-updates"><i class="fa fa-check"></i><b>4.3.3</b> Finding an NMF: Multiplicative Updates</a></li>
<li class="chapter" data-level="4.3.4" data-path="nonnegative-matrix-factorization.html"><a href="nonnegative-matrix-factorization.html#nmf-in-practice"><i class="fa fa-check"></i><b>4.3.4</b> NMF in practice</a></li>
<li class="chapter" data-level="4.3.5" data-path="nonnegative-matrix-factorization.html"><a href="nonnegative-matrix-factorization.html#sec-nmf-ext"><i class="fa fa-check"></i><b>4.3.5</b> Regularization and Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="sec-mds.html"><a href="sec-mds.html"><i class="fa fa-check"></i><b>4.4</b> Multidimensional Scaling</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sec-mds.html"><a href="sec-mds.html#key-features-of-mds"><i class="fa fa-check"></i><b>4.4.1</b> Key features of MDS</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec-mds.html"><a href="sec-mds.html#classical-scaling"><i class="fa fa-check"></i><b>4.4.2</b> Classical Scaling</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec-mds.html"><a href="sec-mds.html#metric-mds"><i class="fa fa-check"></i><b>4.4.3</b> Metric MDS</a></li>
<li class="chapter" data-level="4.4.4" data-path="sec-mds.html"><a href="sec-mds.html#nonmetric-mds"><i class="fa fa-check"></i><b>4.4.4</b> Nonmetric MDS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="kernels-and-nonlinearity.html"><a href="kernels-and-nonlinearity.html"><i class="fa fa-check"></i><b>5</b> Kernels and Nonlinearity</a>
<ul>
<li class="chapter" data-level="5.1" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>5.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch-nonlinear.html"><a href="ch-nonlinear.html"><i class="fa fa-check"></i><b>6</b> Manifold Learning</a>
<ul>
<li class="chapter" data-level="6.1" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>6.1</b> Background</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="background.html"><a href="background.html#data-on-a-manifold"><i class="fa fa-check"></i><b>6.1.1</b> Data on a manifold</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="isometric-feature-map-isomap.html"><a href="isometric-feature-map-isomap.html"><i class="fa fa-check"></i><b>6.2</b> Isometric Feature Map (ISOMAP)</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="isometric-feature-map-isomap.html"><a href="isometric-feature-map-isomap.html#introduction"><i class="fa fa-check"></i><b>6.2.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2.2" data-path="isometric-feature-map-isomap.html"><a href="isometric-feature-map-isomap.html#key-definitions"><i class="fa fa-check"></i><b>6.2.2</b> Key Definitions</a></li>
<li class="chapter" data-level="6.2.3" data-path="isometric-feature-map-isomap.html"><a href="isometric-feature-map-isomap.html#algorithm"><i class="fa fa-check"></i><b>6.2.3</b> Algorithm</a></li>
<li class="chapter" data-level="6.2.4" data-path="isometric-feature-map-isomap.html"><a href="isometric-feature-map-isomap.html#limitations-of-isomap"><i class="fa fa-check"></i><b>6.2.4</b> Limitations of ISOMAP</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="locally-linear-embeddings-lles.html"><a href="locally-linear-embeddings-lles.html"><i class="fa fa-check"></i><b>6.3</b> Locally Linear Embeddings (LLEs)</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="locally-linear-embeddings-lles.html"><a href="locally-linear-embeddings-lles.html#introduction-1"><i class="fa fa-check"></i><b>6.3.1</b> Introduction</a></li>
<li class="chapter" data-level="6.3.2" data-path="locally-linear-embeddings-lles.html"><a href="locally-linear-embeddings-lles.html#algorithm-1"><i class="fa fa-check"></i><b>6.3.2</b> Algorithm</a></li>
<li class="chapter" data-level="6.3.3" data-path="locally-linear-embeddings-lles.html"><a href="locally-linear-embeddings-lles.html#strengths-and-weaknesses-of-lle"><i class="fa fa-check"></i><b>6.3.3</b> Strengths and Weaknesses of LLE</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="autoencoders-aes.html"><a href="autoencoders-aes.html"><i class="fa fa-check"></i><b>6.4</b> Autoencoders (AEs)</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="autoencoders-aes.html"><a href="autoencoders-aes.html#introduction-2"><i class="fa fa-check"></i><b>6.4.1</b> Introduction</a></li>
<li class="chapter" data-level="6.4.2" data-path="autoencoders-aes.html"><a href="autoencoders-aes.html#algorithm-2"><i class="fa fa-check"></i><b>6.4.2</b> Algorithm</a></li>
<li class="chapter" data-level="6.4.3" data-path="autoencoders-aes.html"><a href="autoencoders-aes.html#example"><i class="fa fa-check"></i><b>6.4.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="additional-methods.html"><a href="additional-methods.html"><i class="fa fa-check"></i><b>6.5</b> Additional methods</a></li>
<li class="chapter" data-level="6.6" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch-clustering.html"><a href="ch-clustering.html"><i class="fa fa-check"></i><b>7</b> Clustering</a>
<ul>
<li class="chapter" data-level="7.1" data-path="hierarchical.html"><a href="hierarchical.html"><i class="fa fa-check"></i><b>7.1</b> Hierarchical</a></li>
<li class="chapter" data-level="7.2" data-path="center-based.html"><a href="center-based.html"><i class="fa fa-check"></i><b>7.2</b> Center-based</a></li>
<li class="chapter" data-level="7.3" data-path="model-based.html"><a href="model-based.html"><i class="fa fa-check"></i><b>7.3</b> Model-based</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="model-based.html"><a href="model-based.html#k-means"><i class="fa fa-check"></i><b>7.3.1</b> k-means</a></li>
<li class="chapter" data-level="7.3.2" data-path="model-based.html"><a href="model-based.html#k-mediods"><i class="fa fa-check"></i><b>7.3.2</b> k-mediods</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="spectral.html"><a href="spectral.html"><i class="fa fa-check"></i><b>7.4</b> Spectral</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Unsupervised Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="autoencoders-aes" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Autoencoders (AEs)<a href="autoencoders-aes.html#autoencoders-aes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="introduction-2" class="section level3 hasAnchor" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Introduction<a href="autoencoders-aes.html#introduction-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Autoencoders, emanating from the domain of neural network research, represent a class of unsupervised deep learning models. At its core, autoencoders seek to learn a compressed, efficient representation of input data by leveraging a network structure that encodes the data into a reduced dimensionality and subsequently decodes it to reconstruct the original data.</p>
<p>The typical architecture of an autoencoder comprises three main components:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Encoder</strong>: A function <span class="math inline">\(f(\vec{x})\)</span> that compresses the input <span class="math inline">\(\vec{x}\)</span>s into a latent representation.</p></li>
<li><p><strong>Latent Space</strong>: The reduced dimensionality representation, often denoted as <span class="math inline">\(\vec{z}\)</span>, where <span class="math inline">\(\vec{z} = f(\vec{x})\)</span>.</p></li>
<li><p><strong>Decoder</strong>: A function <span class="math inline">\(g(\vec{z})\)</span> that aims to reconstruct the original input from the latent representation.</p></li>
</ol>
<p>The primary objective during the training phase of an autoencoder is to minimize the reconstruction error, often quantified using metrics such as Mean Squared Error (MSE) between the input data and its reconstructed counterpart. The minimization forces the model to capture salient features of the data in the latent space, thereby enabling efficient data compression, noise reduction, and feature extraction.</p>
<p>The utility of Autoencoders has been demonstrated in a wide array of applications, from dimensionality reduction, anomaly detection, denoising, to more complex tasks such as generating new data instances. Variations and extensions of the basic Autoencoder model, including Variational Autoencoders (VAEs) and Denoising Autoencoders, have further broadened their applicability by introducing probabilistic interpretations and noise robustness, respectively.</p>
<p>In the broader context of machine learning and artificial intelligence, Autoencoders exemplify the power of unsupervised learning paradigms, emphasizing the capability of neural networks to derive meaningful representations from data without explicit labeling.</p>
</div>
<div id="algorithm-2" class="section level3 hasAnchor" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> Algorithm<a href="autoencoders-aes.html#algorithm-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="notations" class="section level4 hasAnchor" number="6.4.2.1">
<h4><span class="header-section-number">6.4.2.1</span> Notations:<a href="autoencoders-aes.html#notations" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Input</strong>
- Dataset <span class="math inline">\(\mathbf{X} = \{\vec{x}_1, \vec{x}_2, \dots, \vec{x}_n\}\)</span> where <span class="math inline">\(\vec{x}_i\)</span> represents each data sample.
- Encoder function with parameters <span class="math inline">\(\theta_e\)</span>: <span class="math inline">\(f_{\theta_e}(x)\)</span>
- Decoder function with parameters <span class="math inline">\(\theta_d\)</span>: <span class="math inline">\(g_{\theta_d}(z)\)</span>
- Objective function to measure reconstruction error, e.g., Mean Squared Error (MSE).</p>
<p><strong>Output</strong>:
- Trained parameters <span class="math inline">\(\theta_e^{\star}\)</span> and <span class="math inline">\(\theta_d^{\star}\)</span> that minimize the reconstruction error.</p>
</div>
<div id="steps-breakdown" class="section level4 hasAnchor" number="6.4.2.2">
<h4><span class="header-section-number">6.4.2.2</span> Steps Breakdown:<a href="autoencoders-aes.html#steps-breakdown" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li><p><strong>Initialization</strong>:</p>
<ul>
<li>Initialize network weights (parameters <span class="math inline">\(\theta_e\)</span> for encoder and <span class="math inline">\(\theta_d\)</span> for decoder) using a method such as Xavier initialization or random initialization.</li>
</ul></li>
<li><p><strong>Forward Pass</strong>:
For each data sample <span class="math inline">\(\vec{x}_i\)</span>:</p>
<ul>
<li>Encode input data sample to get the latent representation:
<span class="math display">\[ \vec{z}_i = f_{\theta_e}(\vec{x}_i) \]</span></li>
<li>Decode the latent representation to get the reconstructed data:
<span class="math display">\[ \vec{x}&#39;_i = g_{\theta_d}(\vec{z}_i) \]</span></li>
</ul></li>
<li><p><strong>Compute Loss</strong>:
Calculate the reconstruction loss for the sample. For example, if using MSE:
<span class="math display">\[ L(\vec{x}_i, \vec{x}&#39;_i) = ||\vec{x}_i - \vec{x}&#39;_i||^2 \]</span>
Accumulate the loss for all samples to get the total loss.</p></li>
<li><p><strong>Backward Pass</strong>:
Using a method like gradient descent or one of its variants (e.g., Adam, RMSProp):</p>
<ul>
<li>Compute the gradients of the loss with respect to the network parameters (<span class="math inline">\(\theta_e\)</span> and <span class="math inline">\(\theta_d\)</span>).</li>
<li>Update the weights in the direction that minimizes the loss.</li>
</ul></li>
<li><p><strong>Iterate</strong>:</p>
<ul>
<li>Repeat steps 2-4 for a predefined number of epochs or until the change in reconstruction error between epochs falls below a specified threshold.</li>
</ul></li>
<li><p><strong>Model Retrieval</strong>:</p>
<ul>
<li>After training, retrieve the encoder <span class="math inline">\(f_{\theta_e^{\star}}\)</span> and decoder <span class="math inline">\(g_{\theta_d^{\star}}\)</span> with the optimal parameters <span class="math inline">\(\theta_e^{\star}\)</span> and <span class="math inline">\(\theta_d^{\star}\)</span>.</li>
</ul></li>
</ol>
</div>
</div>
<div id="example" class="section level3 hasAnchor" number="6.4.3">
<h3><span class="header-section-number">6.4.3</span> Example<a href="autoencoders-aes.html#example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="autoencoders-aes.html#cb25-1" tabindex="-1"></a><span class="co"># # keras provides an interface to the Keras deep learning library in Python</span></span>
<span id="cb25-2"><a href="autoencoders-aes.html#cb25-2" tabindex="-1"></a><span class="co"># library(keras)</span></span>
<span id="cb25-3"><a href="autoencoders-aes.html#cb25-3" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb25-4"><a href="autoencoders-aes.html#cb25-4" tabindex="-1"></a><span class="co"># # load the Minst dataset</span></span>
<span id="cb25-5"><a href="autoencoders-aes.html#cb25-5" tabindex="-1"></a><span class="co"># mnist &lt;- dslabs::read_mnist(</span></span>
<span id="cb25-6"><a href="autoencoders-aes.html#cb25-6" tabindex="-1"></a><span class="co">#   path = NULL,</span></span>
<span id="cb25-7"><a href="autoencoders-aes.html#cb25-7" tabindex="-1"></a><span class="co">#   download = FALSE,</span></span>
<span id="cb25-8"><a href="autoencoders-aes.html#cb25-8" tabindex="-1"></a><span class="co">#   destdir = tempdir(),</span></span>
<span id="cb25-9"><a href="autoencoders-aes.html#cb25-9" tabindex="-1"></a><span class="co">#   url = &quot;https://www2.harvardx.harvard.edu/courses/IDS_08_v2_03/&quot;,</span></span>
<span id="cb25-10"><a href="autoencoders-aes.html#cb25-10" tabindex="-1"></a><span class="co">#   keep.files = TRUE</span></span>
<span id="cb25-11"><a href="autoencoders-aes.html#cb25-11" tabindex="-1"></a><span class="co"># )</span></span>
<span id="cb25-12"><a href="autoencoders-aes.html#cb25-12" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb25-13"><a href="autoencoders-aes.html#cb25-13" tabindex="-1"></a><span class="co"># x_train &lt;- mnist$train$images</span></span>
<span id="cb25-14"><a href="autoencoders-aes.html#cb25-14" tabindex="-1"></a><span class="co"># x_test &lt;- mnist$test$images</span></span></code></pre></div>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="autoencoders-aes.html#cb26-1" tabindex="-1"></a><span class="co"># # Reshape the data and normalize</span></span>
<span id="cb26-2"><a href="autoencoders-aes.html#cb26-2" tabindex="-1"></a><span class="co"># gc()</span></span>
<span id="cb26-3"><a href="autoencoders-aes.html#cb26-3" tabindex="-1"></a><span class="co"># library(reticulate)</span></span>
<span id="cb26-4"><a href="autoencoders-aes.html#cb26-4" tabindex="-1"></a><span class="co"># x_train &lt;- array_reshape(x_train, c(nrow(x_train), 784))</span></span>
<span id="cb26-5"><a href="autoencoders-aes.html#cb26-5" tabindex="-1"></a><span class="co"># x_test &lt;- array_reshape(x_test, c(nrow(x_test), 784))</span></span>
<span id="cb26-6"><a href="autoencoders-aes.html#cb26-6" tabindex="-1"></a><span class="co"># x_train &lt;- x_train / 255</span></span>
<span id="cb26-7"><a href="autoencoders-aes.html#cb26-7" tabindex="-1"></a><span class="co"># x_test &lt;- x_test / 255</span></span></code></pre></div>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="autoencoders-aes.html#cb27-1" tabindex="-1"></a><span class="co"># encoding_dim &lt;- 32  # for compression</span></span>
<span id="cb27-2"><a href="autoencoders-aes.html#cb27-2" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb27-3"><a href="autoencoders-aes.html#cb27-3" tabindex="-1"></a><span class="co"># input_img &lt;- layer_input(shape = c(784))</span></span>
<span id="cb27-4"><a href="autoencoders-aes.html#cb27-4" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb27-5"><a href="autoencoders-aes.html#cb27-5" tabindex="-1"></a><span class="co"># # Encoder layers</span></span>
<span id="cb27-6"><a href="autoencoders-aes.html#cb27-6" tabindex="-1"></a><span class="co"># encoded &lt;- layer_dense(input_img, encoding_dim, activation = &#39;relu&#39;)</span></span>
<span id="cb27-7"><a href="autoencoders-aes.html#cb27-7" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb27-8"><a href="autoencoders-aes.html#cb27-8" tabindex="-1"></a><span class="co"># # Decoder layers</span></span>
<span id="cb27-9"><a href="autoencoders-aes.html#cb27-9" tabindex="-1"></a><span class="co"># decoded &lt;- layer_dense(encoded, 784, activation = &#39;sigmoid&#39;)</span></span>
<span id="cb27-10"><a href="autoencoders-aes.html#cb27-10" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb27-11"><a href="autoencoders-aes.html#cb27-11" tabindex="-1"></a><span class="co"># # Create the autoencoder model</span></span>
<span id="cb27-12"><a href="autoencoders-aes.html#cb27-12" tabindex="-1"></a><span class="co"># autoencoder &lt;- keras_model(input_img, decoded)</span></span></code></pre></div>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="autoencoders-aes.html#cb28-1" tabindex="-1"></a><span class="co"># autoencoder %&gt;% fit(</span></span>
<span id="cb28-2"><a href="autoencoders-aes.html#cb28-2" tabindex="-1"></a><span class="co">#   x_train, x_train,</span></span>
<span id="cb28-3"><a href="autoencoders-aes.html#cb28-3" tabindex="-1"></a><span class="co">#   epochs = 50,</span></span>
<span id="cb28-4"><a href="autoencoders-aes.html#cb28-4" tabindex="-1"></a><span class="co">#   batch_size = 256,</span></span>
<span id="cb28-5"><a href="autoencoders-aes.html#cb28-5" tabindex="-1"></a><span class="co">#   shuffle = TRUE,</span></span>
<span id="cb28-6"><a href="autoencoders-aes.html#cb28-6" tabindex="-1"></a><span class="co">#   validation_data = list(x_test, x_test)</span></span>
<span id="cb28-7"><a href="autoencoders-aes.html#cb28-7" tabindex="-1"></a><span class="co"># )</span></span></code></pre></div>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="autoencoders-aes.html#cb29-1" tabindex="-1"></a><span class="co"># # Get the reconstructed images</span></span>
<span id="cb29-2"><a href="autoencoders-aes.html#cb29-2" tabindex="-1"></a><span class="co"># decoded_imgs &lt;- autoencoder %&gt;% predict(x_test)</span></span>
<span id="cb29-3"><a href="autoencoders-aes.html#cb29-3" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb29-4"><a href="autoencoders-aes.html#cb29-4" tabindex="-1"></a><span class="co"># # Display the original and reconstructed images</span></span>
<span id="cb29-5"><a href="autoencoders-aes.html#cb29-5" tabindex="-1"></a><span class="co"># par(mfrow=c(2,10), mai=c(0.2, 0.2, 0.2, 0.2))</span></span>
<span id="cb29-6"><a href="autoencoders-aes.html#cb29-6" tabindex="-1"></a><span class="co"># for (i in 1:10) {</span></span>
<span id="cb29-7"><a href="autoencoders-aes.html#cb29-7" tabindex="-1"></a><span class="co">#   # Original</span></span>
<span id="cb29-8"><a href="autoencoders-aes.html#cb29-8" tabindex="-1"></a><span class="co">#   img &lt;- array_reshape(x_test[i,], c(28, 28))</span></span>
<span id="cb29-9"><a href="autoencoders-aes.html#cb29-9" tabindex="-1"></a><span class="co">#   image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = &#39;n&#39;, yaxt = &#39;n&#39;, main = &quot;Original&quot;)</span></span>
<span id="cb29-10"><a href="autoencoders-aes.html#cb29-10" tabindex="-1"></a><span class="co">#   # Reconstruction</span></span>
<span id="cb29-11"><a href="autoencoders-aes.html#cb29-11" tabindex="-1"></a><span class="co">#   img &lt;- array_reshape(decoded_imgs[i,], c(28, 28))</span></span>
<span id="cb29-12"><a href="autoencoders-aes.html#cb29-12" tabindex="-1"></a><span class="co">#   image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = &#39;n&#39;, yaxt = &#39;n&#39;, main = &quot;Reconstructed&quot;)</span></span>
<span id="cb29-13"><a href="autoencoders-aes.html#cb29-13" tabindex="-1"></a><span class="co"># }</span></span></code></pre></div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="locally-linear-embeddings-lles.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="additional-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/05-nonlinear_methods.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
