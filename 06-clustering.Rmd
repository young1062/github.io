# Clustering {#ch-clustering}

We now turn to clustering, which is the branch of UL focused on partitioning our data into subgroups of similar observations.  Hereafter, we use the terms clusters and subgroups interchangably.  There are naturally a number of questions which arise including:

i) how many clusters (if any) exist?
ii) what do we mean by similar observations?

As we will see through a series of examples, these two points are linked. Given a notion of similarity (which are implicitly defined for different clustering algorithms and tuneable for others), a certain number of clusters and clustering of data may be optimal. Given a different notion of similarity, an entirely different organization of the data into a different number of clusters may arise. 

For now, let us focus on the the latter question regarding similarity.  Consider the following three examples of data sets in $\mathbb{R}^2$.  Visually, how would you cluster the observations? In particular, how many subgroups would you say exist and how would your partition the data into these subgroups?

::: {.example #cluster-what name="Different notions of similar subgroups"}
```{r fig-cluster-what, fig.align='center', fig.width=10, echo = FALSE}
set.seed(185)
library("MASS")
N <- 200
rho <- 3/4
data1 <- matrix(rnorm(N*2, mean = -2), nrow = N) + matrix((runif(N) < 0.5),nrow = N) %*% matrix(c(4,4),nrow = 1)
data2 <- rbind(mvrnorm(N/2, mu = c(-2,-2), Sigma = matrix(c(1,rho,rho,1),nrow = 2)),
               mvrnorm(N/2, mu = c(2,2), Sigma = matrix(c(1,-rho,-rho,1),nrow = 2)))
data3 <- matrix(rnorm(N*2), nrow = N)
data3 <- diag(1 + (runif(N) < 0.5) + (runif(N) < 0.5)) %*% diag(1/sqrt(diag(data3 %*% t(data3)))) %*% data3
par(mfrow = c(1,3))
plot(data1, xlab = '', ylab = '', main = "Case 1")
plot(data2, xlab = '', ylab = '', main = "Case 2")
plot(data3, xlab = '', ylab = '', main = "Case 3")
```
:::

## Center-based 

### k-means

### k-mediods

## Hierarchical 



## Model-based 


## Spectral